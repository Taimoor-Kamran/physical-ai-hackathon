import os
from openai import OpenAI
from qdrant_client import QdrantClient
from qdrant_client.http.models import FieldCondition, Filter, Range
from backend.src.utils.logging import get_logger
from backend.src.data.qdrant_client import COLLECTION_NAME, get_qdrant_client

# Code generated by Claude Code.
# Co-Authored-By: Claude <noreply@anthropic.com>

logger = get_logger(__name__)

class RAGService:
    def __init__(self):
        self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.qdrant_client: QdrantClient = get_qdrant_client()

    def _get_embedding(self, text: str) -> list[float]:
        response = self.openai_client.embeddings.create(
            input=text,
            model="text-embedding-ada-002"
        )
        return response.data[0].embedding

    def query_rag(self, selected_text: str, query: str | None = None) -> dict:
        combined_query = f"{selected_text} {query}" if query else selected_text
        query_embedding = self._get_embedding(combined_query)

        search_result = self.qdrant_client.query(
            collection_name=COLLECTION_NAME,
            query_vector=query_embedding,
            limit=3, # Retrieve top 3 relevant chunks
            with_payload=True,
        )

        context = []
        source_context = []
        for hit in search_result.hits:
            context.append(hit.payload["text"])
            source_context.append(hit.payload["metadata"])

        context_str = "\n\n".join(context)
        full_prompt = f"""Based on the following context, answer the question.\n\nContext:\n{context_str}\n\nQuestion: {combined_query}\nAnswer:"""

        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": full_prompt}],
            )
            answer = response.choices[0].message.content
        except Exception as e:
            logger.error(f"Error calling OpenAI API: {e}")
            answer = "I am sorry, but I could not retrieve an answer at this time."

        return {"answer": answer, "source_context": source_context}
