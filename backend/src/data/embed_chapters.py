import os
import glob
import markdown_it
from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv
from qdrant_client.http.models import PointStruct, models
from ..utils.logging import get_logger
from .qdrant_client import get_qdrant_client, initialize_qdrant_collection, QDRANT_COLLECTION_NAME

# Code generated by Claude Code.
# Co-Authored-By: Claude <noreply@anthropic.com>

logger = get_logger(__name__)

load_dotenv()
embedding_model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu', cache_folder='models')

# Initialize Markdown parser
md = markdown_it.MarkdownIt()

def get_mdx_content(file_path: str) -> str:
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    # Remove MDX specific syntax (e.g., import statements, export defaults)
    # This is a basic removal and might need more sophistication for complex MDX
    content = '\n'.join([line for line in content.split('\n') if not (
        line.strip().startswith('import') or
        line.strip().startswith('export default') or
        line.strip().startswith('---')
    )])
    return content

def markdown_to_text(markdown_text: str) -> str:
    return md.render(markdown_text)

def chunk_text(text: str, chunk_size: int = 1000, overlap: int = 200) -> list[str]:
    chunks = []
    current_chunk = []
    current_length = 0

    sentences = text.split('. ') # Basic sentence splitting

    for sentence in sentences:
        sentence_length = len(sentence) + 2 # +2 for '. '

        if current_length + sentence_length <= chunk_size:
            current_chunk.append(sentence)
            current_length += sentence_length
        else:
            chunks.append('. '.join(current_chunk) + '.')
            current_chunk = [sentence]
            current_length = sentence_length

    if current_chunk:
        chunks.append('. '.join(current_chunk) + '.')

    return chunks

def embed_chapters():
    qdrant_client = get_qdrant_client()
    initialize_qdrant_collection(qdrant_client) # Use default vector_size

    mdx_files = glob.glob("../frontend/docs/**/*.mdx", recursive=True)
    logger.info(f"Found {len(mdx_files)} MDX files to embed.")

    points = []
    for file_path in mdx_files:
        logger.info(f"Processing file: {file_path}")
        mdx_content = get_mdx_content(file_path)
        plain_text = markdown_to_text(mdx_content)
        chunks = chunk_text(plain_text)

        for i, chunk in enumerate(chunks):
            try:
                embedding = embedding_model.encode(chunk).tolist()

                points.append(
                    PointStruct(
                        vector=embedding,
                        payload={
                            "text": chunk,
                            "metadata": {
                                "file_path": file_path,
                                "chunk_index": i
                            }
                        }
                    )
                )
            except Exception as e:
                logger.error(f"Error embedding chunk from {file_path}, chunk {i}: {e}")

    if points:
        qdrant_client.upsert(
            collection_name=QDRANT_COLLECTION_NAME,
            wait=True,
            points=points
        )
        logger.info(f"Successfully embedded and upserted {len(points)} points into Qdrant.")
    else:
        logger.info("No points to upsert.")

if __name__ == "__main__":
    embed_chapters()
